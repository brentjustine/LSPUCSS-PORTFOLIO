

# === ai.py ===
import os
import httpx
from dotenv import load_dotenv
from utils import extract_text_from_file_url

load_dotenv()

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
HEADERS = {
    "Authorization": f"Bearer {GROQ_API_KEY}",
    "Content-Type": "application/json"
}

async def generate_ai_score() -> float:
    return 9.0

async def generate_suggestions(description: str, file_url: str | None = None) -> str:
    file_content = await extract_text_from_file_url(file_url) if file_url else ""
    payload = {
        "model": "llama3-8b-8192",
        "messages": [
            {"role": "system", "content": "You are a helpful AI tutor that gives project improvement suggestions."},
            {"role": "user", "content": f"Project description: {description}\n\nFile contents: {file_content}\n\nWhat are some suggestions for improving this project?"}
        ],
        "temperature": 0.7
    }
    async with httpx.AsyncClient() as client:
        res = await client.post(GROQ_API_URL, headers=HEADERS, json=payload)
        res.raise_for_status()
        return res.json()["choices"][0]["message"]["content"].strip()

async def suggest_learning_path(title: str, description: str = "", file_url: str | None = None) -> str:
    file_content = await extract_text_from_file_url(file_url) if file_url else ""
    payload = {
        "model": "llama3-8b-8192",
        "messages": [
            {"role": "system", "content": "You are a learning path recommendation assistant for programming students."},
            {"role": "user", "content": f"Title: {title}\nDescription: {description}\n\nFile content: {file_content}\n\nWhat should I learn next?"}
        ],
        "temperature": 0.7
    }
    async with httpx.AsyncClient() as client:
        res = await client.post(GROQ_API_URL, headers=HEADERS, json=payload)
        res.raise_for_status()
        return res.json()["choices"][0]["message"]["content"].strip()

async def summarize_overall_insights(projects: list) -> str:
    content = "\n\n".join([f"Title: {p['title']}\nDescription: {p['description']}\nSuggestions: {p.get('ai_suggestions', '')}" for p in projects])
    prompt = f"""
    You are an AI tutor evaluating a student's project portfolio. Below are several projects they submitted:

    {content}

    Summarize the student's overall strengths and weaknesses, and provide recommendations on how they can improve.
    """

    payload = {
        "model": "llama3-8b-8192",
        "messages": [
            {"role": "system", "content": "You are a helpful AI tutor that summarizes student performance."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7
    }

    async with httpx.AsyncClient() as client:
        res = await client.post(GROQ_API_URL, headers=HEADERS, json=payload)
        res.raise_for_status()
        return res.json()["choices"][0]["message"]["content"].strip()


# === database.py ===
import os
from dotenv import load_dotenv
from supabase import create_client, Client

load_dotenv()

SUPABASE_URL: str | None = os.getenv("SUPABASE_URL")
SUPABASE_KEY: str | None = os.getenv("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    raise EnvironmentError("Missing SUPABASE_URL or SUPABASE_KEY in your .env file.")

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# === main.py ===
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from routes import router

app = FastAPI(title="Student Portfolio API", version="0.1.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(router)

# === models.py ===
from sqlalchemy import Column, Integer, String
from database import Base

class Project(Base):
    __tablename__ = "projects"
    id = Column(Integer, primary_key=True, index=True)
    student_name = Column(String)
    title = Column(String)
    description = Column(String)

class User(Base):
    __tablename__ = "users"
    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True)
    password = Column(String)


# === routes.py ===
from fastapi import APIRouter, HTTPException, Request
from schemas import ProjectIn, ProjectOut
from ai import (
    generate_ai_score,
    generate_suggestions,
    suggest_learning_path,
    summarize_overall_insights,
)
from database import supabase

router = APIRouter()


# 🔄 Return AI feedback only — frontend handles database insert
@router.post("/submit")
async def submit_project(project: ProjectIn):
    try:
        ai_score = await generate_ai_score()
        ai_suggestions = await generate_suggestions(project.description, project.file_url)
        ai_learning_path = await suggest_learning_path(
            project.title, project.description, project.file_url
        )

        return {
            "ai_score": ai_score,
            "ai_suggestions": ai_suggestions,
            "ai_learning_path": ai_learning_path,
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# 📦 Return all projects, newest first
@router.get("/projects", response_model=list[ProjectOut])
async def get_projects():
    try:
        response = supabase.table("projects").select("*").order("created_at", desc=True).execute()
        data = response.data or []
        for item in data:
            item["student_name"] = item.get("student_name") or "Unnamed Student"
        return data
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# 🧠 Return learning path suggestion using AI
@router.get("/suggestion")
async def get_suggestion(title: str):
    try:
        suggestion = await suggest_learning_path(title)
        return {"suggestion": suggestion}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# 📊 Return AI-generated summary of all user projects (cached if available)
@router.get("/summary")
async def get_summary(request: Request):
    try:
        user_id = request.query_params.get("user_id")
        if not user_id:
            raise HTTPException(status_code=400, detail="Missing user_id")

        print(f"🔍 Getting summary for user_id={user_id}")

        # 🧼 Check if user still has projects
        response = supabase.table("projects").select("*").eq("user_id", user_id).execute()
        projects = response.data or []
        if not projects:
            print("🚫 No projects found. Skipping summary.")
            raise HTTPException(status_code=404, detail="No projects found for summary.")

        # ✅ Use cached summary if available
        cached = supabase.table("user_summaries").select("*").eq("user_id", user_id).limit(1).execute()
        if cached.data and len(cached.data) > 0:
            print("✅ Using cached summary")
            return {"summary": cached.data[0]["summary"]}

        # ⏳ Generate new summary
        summary = await summarize_overall_insights(projects)
        if not summary:
            raise HTTPException(status_code=500, detail="AI failed to generate summary")

        # 💾 Cache it
        supabase.table("user_summaries").upsert({
            "user_id": user_id,
            "summary": summary
        }).execute()

        return {"summary": summary}

    except Exception as e:
        print("❌ Summary error:", e)
        raise HTTPException(status_code=500, detail=str(e))



# === schemas.py ===
from pydantic import BaseModel
from typing import Optional

class ProjectIn(BaseModel):
    student_name: str
    title: str
    description: str
    file_url: Optional[str] = None

class ProjectOut(ProjectIn):
    id: int
    student_name: Optional[str]

# === utils.py ===
# utils.py
import os
import tempfile
import zipfile
import httpx
import mimetypes
from pathlib import Path
from docx import Document
from PyPDF2 import PdfReader

async def extract_text_from_file_url(file_url: str) -> str:
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(file_url)
            response.raise_for_status()

            file_type = mimetypes.guess_type(file_url)[0] or ""
            ext = Path(file_url).suffix.lower()

            with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
                tmp.write(response.content)
                tmp_path = tmp.name

        if ext == ".zip":
            return extract_text_from_zip(tmp_path)
        elif ext == ".docx":
            return extract_text_from_docx(tmp_path)
        elif ext == ".pdf":
            return extract_text_from_pdf(tmp_path)
        elif ext in [".py", ".js", ".ts", ".java", ".html", ".css", ".txt", ".md"]:
            return extract_text_from_plain(tmp_path)
        else:
            return f"(Unsupported file type: {ext})"

    except Exception as e:
        return f"(Failed to extract file content: {str(e)})"

def extract_text_from_plain(path: str) -> str:
    with open(path, "r", encoding="utf-8", errors="ignore") as f:
        return f.read()

def extract_text_from_docx(path: str) -> str:
    doc = Document(path)
    return "\n".join([para.text for para in doc.paragraphs])

def extract_text_from_pdf(path: str) -> str:
    reader = PdfReader(path)
    return "\n".join([page.extract_text() or "" for page in reader.pages])

def extract_text_from_zip(path: str) -> str:
    output = []
    with zipfile.ZipFile(path, "r") as zip_ref:
        for file_info in zip_ref.infolist():
            if file_info.filename.endswith((".txt", ".py", ".md", ".js", ".ts", ".html", ".css")):
                with zip_ref.open(file_info) as f:
                    try:
                        output.append(f"\n--- {file_info.filename} ---\n" + f.read().decode("utf-8", errors="ignore"))
                    except Exception:
                        continue
    return "\n".join(output)
